# -*- coding: utf-8 -*-
"""WineQuality.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zukppgo2_NkpucSlzLNtetOcOlfL0_5q
"""

!wget https://goo.gl/8jsvFK

!ls

!cat 8jsvFK

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

wine_quality_dataset = pd.read_csv("8jsvFK", sep=';')
wine_quality_dataset.head()

import seaborn as sns

sns.pairplot(wine_quality_dataset[wine_quality_dataset.columns], height = 2)
plt.tight_layout()
plt.show()

# As we can see this dataset does not look very linear so a linear regression model
# isnt the best here however it is the one that we want to practice implementing

from sklearn import preprocessing


min_max_scalar = preprocessing.MinMaxScaler()

weights = np.random.normal(1,1,(12))
X = np.asarray(wine_quality_dataset.iloc[:,0:11])
scaled = min_max_scalar.fit_transform(X)
X = pd.DataFrame(scaled)
temp = np.ones((len(X), 12))
temp[:,1:12] = X
X = temp

Y = np.asarray(wine_quality_dataset.iloc[:,-1:])

print(np.asscalar(Y[1:1+1]))

def predict(row, coefficients):
  return np.dot(row, coefficients)

errors = []
def gradient_descent(weights, l_rate = 0.01, epochs=10):
  for epoch in range(epochs):
    for row in range(len(X)):
      error = predict(X[row], weights) - np.asscalar(Y[row:row+1])
      errors.append(error)
      weights = weights - (l_rate / len(X)) * error * X[row]
  return weights

weights = gradient_descent(weights)
print(predict(X[1], weights))
plt.plot(errors)

print(weights)
# This algorithm works almost as well as the one below so I believe that this works stochastically
# However the WineQualityDataset is just not very linear.

# ATTEMPT NUMBER 2 Stochastically

# Separate our dataset information.
X = np.asarray(wine_quality_dataset.iloc[:,0:11])
Y = np.asarray(wine_quality_dataset.iloc[:,-1:])

# number of columns in X plus our bias.
weights = np.zeros(1 + X.shape[1])
print(weights.shape)

# Create a history of the cost function for later use.
cost_history = []

# Using Linear Algebra to Solve this problem quickly
X_b = np.hstack((np.ones((X.shape[0],1)), X))
z = np.linalg.inv(np.dot(X_b.T, X_b))
weights = np.dot(z, np.dot(X_b.T, Y))


print(weights)

def predict(row):
  print(row.shape)
  sum = weights[0]
  for i in range(1,11):
    sum += row[0][i-1] * weights[i]
  return sum

